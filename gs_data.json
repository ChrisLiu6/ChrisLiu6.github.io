{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "VxQGEOcAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Dongyang Liu", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=VxQGEOcAAAAJ&citpid=1", "affiliation": "MMLab CUHK", "interests": [], "email_domain": "@link.cuhk.edu.hk", "citedby": 1432, "publications": {"VxQGEOcAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Llama-adapter: Efficient fine-tuning of language models with zero-init attention", "pub_year": "2023"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:zYLM7Y9cAGgC", "num_citations": 808, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=115732250789891516", "cites_id": ["115732250789891516"]}, "VxQGEOcAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sphinx: The joint mixing of weights, tasks, and visual embeddings for multi-modal large language models", "pub_year": "2023"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:_FxGoFyzp5QC", "num_citations": 232, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=809090494406335144", "cites_id": ["809090494406335144"]}, "VxQGEOcAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Imagebind-llm: Multi-modality instruction tuning", "pub_year": "2023"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:Tyk-4Ss8FVUC", "num_citations": 133, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7633131358609482991", "cites_id": ["7633131358609482991"]}, "VxQGEOcAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:UeHWp8X0CEIC", "num_citations": 119, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=891412887268659419", "cites_id": ["891412887268659419"]}, "VxQGEOcAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-mgpt: Illuminate flexible photorealistic text-to-image generation with multimodal generative pretraining", "pub_year": "2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:eQOLeE2rZwMC", "num_citations": 48, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1388206220295129761", "cites_id": ["1388206220295129761"]}, "VxQGEOcAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Function-consistent feature distillation", "pub_year": "2023"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:d1gkVwhDpl0C", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16320296499653959319", "cites_id": ["16320296499653959319"]}, "VxQGEOcAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-t2x: Transforming text into any modality, resolution, and duration via flow-based large diffusion transformers", "pub_year": "2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:Y0pCki6q_DkC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14417271216765405515", "cites_id": ["14417271216765405515"]}, "VxQGEOcAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Venhancer: Generative space-time enhancement for video generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:YsMSGLbcyi4C", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5804655861025015765", "cites_id": ["5804655861025015765"]}, "VxQGEOcAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Seamless 3D surround view with a novel burger model", "pub_year": "2019"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:2osOgNQ5qMEC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12750619661039030326", "cites_id": ["12750619661039030326"]}, "VxQGEOcAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Simple Romance Between Multi-Exit Vision Transformer and Token Reduction", "pub_year": "2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:u-x6o8ySG0sC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5623049777377271110", "cites_id": ["5623049777377271110"]}, "VxQGEOcAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-next: Making lumina-t2x stronger and faster with next-dit", "pub_year": "2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:W7OEmFMy1HYC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15035790787388684947", "cites_id": ["15035790787388684947"]}, "VxQGEOcAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Triplet knowledge distillation", "pub_year": "2023"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:9yKSN-GCB0IC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3628776661537282219", "cites_id": ["3628776661537282219"]}, "VxQGEOcAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "I-max: Maximize the resolution potential of pre-trained rectified flow transformers with projected flow", "pub_year": "2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:LkGwnXOMwfcC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15458979330695158963", "cites_id": ["15458979330695158963"]}, "VxQGEOcAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SPHINX: A Mixer of Weights, Visual Embeddings and Image Scales for Multi-modal Large Language Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:0EnyYjriUFMC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1563414452343144744", "cites_id": ["1563414452343144744"]}, "VxQGEOcAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "OmniCaptioner: One Captioner to Rule Them All", "pub_year": "2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:5nxA0vEk-isC", "num_citations": 0}, "VxQGEOcAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LeX-Art: Rethinking Text Generation via Scalable High-Quality Data Synthesis", "pub_year": "2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:hqOjcs7Dif8C", "num_citations": 0}, "VxQGEOcAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-Image 2.0: A Unified and Efficient Image Generative Framework", "pub_year": "2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:UebtZRa9Y70C", "num_citations": 0}, "VxQGEOcAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT", "pub_year": "2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:roLk4NBRz8UC", "num_citations": 0}, "VxQGEOcAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-T2X: Scalable Flow-based Large Diffusion Transformer for Flexible Resolution Generation"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:Se3iqnhoufwC", "num_citations": 0}}, "citedby5y": 1431, "hindex": 9, "hindex5y": 9, "i10index": 9, "i10index5y": 9, "cites_per_year": {"2023": 192, "2024": 951, "2025": 277}, "updated": "2025-04-19 08:09:54.457058"}