{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "VxQGEOcAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Dongyang Liu", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=VxQGEOcAAAAJ&citpid=1", "affiliation": "MMLab CUHK", "interests": ["Image/Video Generation", "LLMs", "VLMs"], "email_domain": "@link.cuhk.edu.hk", "homepage": "http://chrisliu6.github.io/", "citedby": 2089, "publications": {"VxQGEOcAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Llama-adapter: Efficient fine-tuning of language models with zero-init attention", "pub_year": "2023", "citation": "arXiv preprint arXiv:2303.16199, 2023"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:zYLM7Y9cAGgC", "num_citations": 1026, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=115732250789891516", "cites_id": ["115732250789891516"]}, "VxQGEOcAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sphinx: The joint mixing of weights, tasks, and visual embeddings for multi-modal large language models", "pub_year": "2023", "citation": "ECCV 2024, 2023"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:_FxGoFyzp5QC", "num_citations": 338, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=809090494406335144,1563414452343144744", "cites_id": ["809090494406335144", "1563414452343144744"]}, "VxQGEOcAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Imagebind-llm: Multi-modality instruction tuning", "pub_year": "2023", "citation": "arXiv preprint arXiv:2309.03905, 2023"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:Tyk-4Ss8FVUC", "num_citations": 190, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7633131358609482991", "cites_id": ["7633131358609482991"]}, "VxQGEOcAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models", "pub_year": "2024", "citation": "Forty-first International Conference on Machine Learning, 2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:UeHWp8X0CEIC", "num_citations": 168, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=891412887268659419", "cites_id": ["891412887268659419"]}, "VxQGEOcAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-mgpt: Illuminate flexible photorealistic text-to-image generation with multimodal generative pretraining", "pub_year": "2024", "citation": "arXiv preprint arXiv:2408.02657, 2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:eQOLeE2rZwMC", "num_citations": 115, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1388206220295129761", "cites_id": ["1388206220295129761"]}, "VxQGEOcAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-T2X: Scalable Flow-based Large Diffusion Transformer for Flexible Resolution Generation", "pub_year": "2025", "citation": "The Thirteenth International Conference on Learning Representations, 2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:Se3iqnhoufwC", "num_citations": 48, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14417271216765405515,1927540231778473314,8033076143114662575", "cites_id": ["14417271216765405515", "1927540231778473314", "8033076143114662575"]}, "VxQGEOcAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Venhancer: Generative space-time enhancement for video generation", "pub_year": "2024", "citation": "arXiv preprint arXiv:2407.07667, 2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:YsMSGLbcyi4C", "num_citations": 47, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5804655861025015765", "cites_id": ["5804655861025015765"]}, "VxQGEOcAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Function-consistent feature distillation", "pub_year": "2023", "citation": "ICLR 2023, 2023"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:d1gkVwhDpl0C", "num_citations": 44, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16320296499653959319", "cites_id": ["16320296499653959319"]}, "VxQGEOcAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-mgpt 2.0: Stand-alone autoregressive image modeling", "pub_year": "2025", "citation": "arXiv preprint arXiv:2507.17801, 2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:8k81kl-MbHgC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13311945729466637798", "cites_id": ["13311945729466637798"]}, "VxQGEOcAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-next: Making lumina-t2x stronger and faster with next-dit", "pub_year": "2024", "citation": "Advances in Neural Information Processing Systems 37, 131278-131315, 2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:W7OEmFMy1HYC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15035790787388684947", "cites_id": ["15035790787388684947"]}, "VxQGEOcAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Simple Romance Between Multi-Exit Vision Transformer and Token Reduction", "pub_year": "2024", "citation": "The Twelfth International Conference on Learning Representations, 2024"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:u-x6o8ySG0sC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5623049777377271110", "cites_id": ["5623049777377271110"]}, "VxQGEOcAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Omnicaptioner: One captioner to rule them all", "pub_year": "2025", "citation": "arXiv preprint arXiv:2504.07089, 2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:5nxA0vEk-isC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8570511121205308811", "cites_id": ["8570511121205308811"]}, "VxQGEOcAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Seamless 3D surround view with a novel burger model", "pub_year": "2019", "citation": "2019 IEEE International Conference on Image Processing (ICIP), 4150-4154, 2019"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:2osOgNQ5qMEC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12750619661039030326", "cites_id": ["12750619661039030326"]}, "VxQGEOcAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-image 2.0: A unified and efficient image generative framework", "pub_year": "2025", "citation": "arXiv preprint arXiv:2503.21758, 2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:UebtZRa9Y70C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8531898801516477538", "cites_id": ["8531898801516477538"]}, "VxQGEOcAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumina-video: Efficient and flexible video generation with multi-scale next-dit", "pub_year": "2025", "citation": "arXiv preprint arXiv:2502.06782, 2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:roLk4NBRz8UC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1644127670175797638", "cites_id": ["1644127670175797638"]}, "VxQGEOcAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "I-max: Maximize the resolution potential of pre-trained rectified flow transformers with projected flow", "pub_year": "2024", "citation": ""}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:LkGwnXOMwfcC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15458979330695158963", "cites_id": ["15458979330695158963"]}, "VxQGEOcAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LeX-Art: Rethinking Text Generation via Scalable High-Quality Data Synthesis", "pub_year": "2025", "citation": "arXiv preprint arXiv:2503.21749, 2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:hqOjcs7Dif8C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14946858081304700675", "cites_id": ["14946858081304700675"]}, "VxQGEOcAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Triplet knowledge distillation", "pub_year": "2023", "citation": "arXiv preprint arXiv:2305.15975, 2023"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:9yKSN-GCB0IC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3628776661537282219", "cites_id": ["3628776661537282219"]}, "VxQGEOcAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer", "pub_year": "2025", "citation": "arXiv preprint arXiv:2511.22699, 2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:KlAtU1dfN6UC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16182983139179141473", "cites_id": ["16182983139179141473"]}, "VxQGEOcAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Decoupled DMD: CFG Augmentation as the Spear, Distribution Matching as the Shield", "pub_year": "2025", "citation": "arXiv preprint arXiv:2511.22677, 2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:kNdYIx-mwKoC", "num_citations": 0}, "VxQGEOcAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Distribution Matching Distillation Meets Reinforcement Learning", "pub_year": "2025", "citation": "arXiv preprint arXiv:2511.13649, 2025"}, "filled": false, "author_pub_id": "VxQGEOcAAAAJ:3fE2CSJIrl8C", "num_citations": 0}}, "citedby5y": 2087, "hindex": 12, "hindex5y": 12, "i10index": 13, "i10index5y": 13, "cites_per_year": {"2023": 177, "2024": 877, "2025": 992, "2026": 31}, "updated": "2026-01-23 08:30:17.118508"}